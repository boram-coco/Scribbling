[
  {
    "objectID": "posts/VAE.html",
    "href": "posts/VAE.html",
    "title": "VAE(-ing)",
    "section": "",
    "text": "https://arxiv.org/pdf/1312.6114.pdf"
  },
  {
    "objectID": "posts/VAE.html#ì˜¤í† ì¸ì½”ë”",
    "href": "posts/VAE.html#ì˜¤í† ì¸ì½”ë”",
    "title": "VAE(-ing)",
    "section": "ì˜¤í† ì¸ì½”ë”",
    "text": "ì˜¤í† ì¸ì½”ë”\n\nEncoder, Decoder ë„¤íŠ¸ì›Œí¬ë¡œ êµ¬ì„±ëœ ëª¨ë¸\ní•™ìŠµ ë°ì´í„°-> encoderì— ì…ë ¥ê°’"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "",
    "text": "í•´ë‹¹ ìë£ŒëŠ” ì „ë¶ëŒ€í•™êµ ì´ì˜ë¯¸ êµìˆ˜ë‹˜ 2023ì‘ìš©í†µê³„í•™ ìë£Œì„"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#leverage-vs.-outlier-vs.-influence",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#leverage-vs.-outlier-vs.-influence",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "Leverage vs.Â Outlier vs.Â Influence",
    "text": "Leverage vs.Â Outlier vs.Â Influence\n\nlibrary(lmtest)\n\nLoading required package: zoo\n\n\nAttaching package: â€˜zooâ€™\n\n\nThe following objects are masked from â€˜package:baseâ€™:\n\n    as.Date, as.Date.numeric\n\n\n\n\n\ndt <- data.frame(x = c(15,26,10,9,15,20,18,11,\n 8,20,7,9,10,11,11,10,12,42,17,11,10),\n y = c(95,71,83,91,102,87,93,100,\n 104,94,113,96,83,84,102,100,\n 105,57,121,86,100))\n\n\n######## ì‚°ì ë„\nplot(y~x, dt,pch = 20,cex = 2,col = \"darkorange\")"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#íšŒê·€ëª¨í˜•-ì í•©-ybeta_0-beta_1x-epsilon",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#íšŒê·€ëª¨í˜•-ì í•©-ybeta_0-beta_1x-epsilon",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "íšŒê·€ëª¨í˜• ì í•©: \\(y=\\beta_0+ \\beta_1x + \\epsilon\\)",
    "text": "íšŒê·€ëª¨í˜• ì í•©: \\(y=\\beta_0+ \\beta_1x + \\epsilon\\)\n\n######## íšŒê·€ì í•©\nmodel_reg <- lm(y~x, dt)\nsummary(model_reg)\n\n\nCall:\nlm(formula = y ~ x, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.604  -8.731   1.396   4.523  30.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 109.8738     5.0678  21.681 7.31e-15 ***\nx            -1.1270     0.3102  -3.633  0.00177 ** \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 11.02 on 19 degrees of freedom\nMultiple R-squared:   0.41, Adjusted R-squared:  0.3789 \nF-statistic:  13.2 on 1 and 19 DF,  p-value: 0.001769\n\n\n\nplot(y~x, dt,pch = 20,cex = 2,col = \"darkorange\")\nabline(model_reg, col='steelblue', lwd=2)"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#hat-matrix",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#hat-matrix",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "Hat Matrix",
    "text": "Hat Matrix\n\nX = cbind(rep(1, nrow(dt)), dt$x)\nH = X %*% solve(t(X) %*% X) %*% t(X)\ndiag(H)\n\n\n0.04792247945102180.1545132342960560.06281577558253530.07054520775205490.04792247945102180.07261895784631620.05798959354498150.05666993439408790.07985823090264690.07261895784631620.09075484503431120.07054520775205490.06281577558253530.05666993439408790.05666993439408790.06281577558253530.05210768418671290.651609984164090.05305029786592260.05666993439408790.0628157755825353\n\n\n\nsum(diag(H))\n\n2\n\n\n\nhatvalues(model_reg)\n\n10.047922479451021820.15451323429605630.062815775582535340.070545207752054950.047922479451021860.072618957846316370.057989593544981580.056669934394087990.0798582309026469100.0726189578463163110.0907548450343111120.0705452077520549130.0628157755825353140.0566699343940879150.0566699343940879160.0628157755825353170.0521076841867129180.65160998416409190.0530502978659226200.0566699343940879210.0628157755825353\n\n\n\nwhich.max(hatvalues(model_reg))\nhatvalues(model_reg)[which.max(hatvalues(model_reg))] ##h_{18,18}\n\n18: 18\n\n\n18: 0.65160998416409\n\n\n\n2*(1+1)/nrow(dt)\n\n0.19047619047619\n\n\n\n\\(h_{18,18} > 2 \\bar h\\)ì´ë¯€ë¡œ 18ë²ˆì§¸ ê´€ì¸¡ê°’ì´ leverage point ë¡œ ê³ ë ¤ ê°€ëŠ¥\n\n\nplot(y~x, dt,pch = 20,cex = 2,col = \"darkorange\")\ntext(dt[18,],\"18\", pos=2)\nabline(model_reg, col='steelblue', lwd=2)"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì”ì°¨-e_i-y_i---hat-y_i",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì”ì°¨-e_i-y_i---hat-y_i",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "ì”ì°¨: \\(e_i = y_i - \\hat y_i\\)",
    "text": "ì”ì°¨: \\(e_i = y_i - \\hat y_i\\)\n\nresidual <- model_reg$residuals\nhead(residual)\n\n12.030993137772482-9.572128798733133-15.60395143654324-8.7309403514063859.030993137772416-0.334062287911925\n\n\n\nhist(residual)"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ë‚´ì ìœ¼ë¡œ-í‘œì¤€í™”ëœ-ì”ì°¨-internally-standardized-residual",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ë‚´ì ìœ¼ë¡œ-í‘œì¤€í™”ëœ-ì”ì°¨-internally-standardized-residual",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "ë‚´ì ìœ¼ë¡œ í‘œì¤€í™”ëœ ì”ì°¨ ((internally) standardized residual)",
    "text": "ë‚´ì ìœ¼ë¡œ í‘œì¤€í™”ëœ ì”ì°¨ ((internally) standardized residual)\n\\[r_i = \\dfrac{e_i}{\\hat \\sigma \\sqrt{1-h_{ii}}}\\]\n\ns_residual <- rstandard(model_reg)\nhead(s_residual)\n\n10.1888322174200252-0.9444063949896653-1.462264369447094-0.82158155071330550.8396593902729546-0.0314703908632008\n\n\n\n# ë˜ëŠ”\ns_xx <- sum((dt$x-mean(dt$x))^2) #S_xx\nh_ii <- 1/21 + (dt$x- mean(dt$x))^2/s_xx\n### h_ii <- hatvalues(model_reg)\n### h_ii <- influence(model_reg)$hat\nhat_sigma <- summary(model_reg)$sigma #hat sigma\ns_residual <- resid(model_reg)/(hat_sigma*sqrt(1-h_ii)) ## ë‚´ì \n\n\nhist(s_residual)"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì™¸ì ìœ¼ë¡œ-í‘œì¤€í™”ëœ-ì”ì°¨-externally-standardized-residual",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì™¸ì ìœ¼ë¡œ-í‘œì¤€í™”ëœ-ì”ì°¨-externally-standardized-residual",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "ì™¸ì ìœ¼ë¡œ í‘œì¤€í™”ëœ ì”ì°¨ ((externally) standardized residual)",
    "text": "ì™¸ì ìœ¼ë¡œ í‘œì¤€í™”ëœ ì”ì°¨ ((externally) standardized residual)\n\\[r_i^* = \\dfrac{e_i}{\\hat \\sigma_i \\sqrt{1-h_{ii}}}\\]\n\\(\\hat \\sigma_i : i\\)ë²ˆì§¸ ì¸¡ì •ê°’ \\(y_i\\)ë¥¼ ì œì™¸í•˜ê³  ì–»ì–´ì§„ \\(\\hat \\sigma\\)\n\\(\\hat \\sigma_i^2 = \\left[ (n-p-1) \\hat \\sigma^2 - \\dfrac{e_i^2}{1-h_{ii}} \\right] / (n-p-2)\\)\n\ns_residual_i <- rstudent(model_reg)\nhead(s_residual_i)\n\n10.1839684933793942-0.9415833513782013-1.510811922917994-0.81426336315943850.8328629175207956-0.030631827537088\n\n\n\n# ë˜ëŠ”\nhat_sigma_i <- sqrt(((21-1-1)*hat_sigma^2 - residual^2/(1-h_ii) )/(21-1-2))\n## hat_sigma_i <- influence(model_reg)$sigma\ns_residual_i <- residual/(hat_sigma_i*sqrt(1-h_ii)) ## ì™¸ì \n\n\nhist(s_residual_i)\n\n\n\n\n\nwhich.max(s_residual_i)\ns_residual_i[which.max(s_residual_i)]\n\n19: 19\n\n\n19: 3.60697972130439\n\n\n\nqt(0.975, 21-1-2)\n\n2.10092204024104\n\n\n\\(|r_i^*| \\geq t_{\\alpha/2}(n-p-2)\\)ì´ë©´, ìœ ì˜ìˆ˜ì¤€ \\(\\alpha\\)ì—ì„œ, \\(i\\)ë²ˆì§¸ ê´€ì¸¡ê°’ì´ ì´ìƒì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.\në”°ë¼ì„œ 19ë²ˆì§¸ ê´€ì¸¡ê°’ì€ ìœ ì˜ìˆ˜ì¤€ 0.05ì—ì„œ ì´ìƒì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.\n\nplot(y~x, dt,pch = 20,cex = 2,col = \"darkorange\")\ntext(dt[19,],\"19\", pos=2)\nabline(model_reg, col='steelblue', lwd=2)\n\n\n\n\n\ns_residual_i[which(abs(s_residual_i)>qt(0.975,21-2))]\n\n19: 3.60697972130439\n\n\n\n## ì”ì°¨ê·¸ë¦¼\npar(mfrow = c(2, 2))\nplot(fitted(model_reg), residual,\n pch=20,cex = 2,col = \"darkorange\",\n xlab = \"Fitted\", ylab = \"Residuals\",\n main = \"residual plot\")\nabline(h=0, lty=2)\nplot(fitted(model_reg), s_residual,\n pch=20,cex = 2,col = \"darkorange\",\n xlab = \"Fitted\", ylab = \"S_Residuals\",\n ylim=c(min(-3, min(s_residual)),\n max(3,max(s_residual))),\n main = \"standardized residual plot\")\nabline(h=c(-2,0,2), lty=2)\nplot(fitted(model_reg), s_residual_i,\n pch=20,cex = 2,col = \"darkorange\",\n xlab = \"Fitted\", ylab = \"S_Residuals_(i)\",\n ylim=c(min(-3, min(s_residual_i)),\n max(3,max(s_residual_i))),\n main = \"studentized residual plot\")\nabline(h=c(-3,-2,0,2,3), lty=2)\nplot(fitted(model_reg), s_residual_i,\n pch=20,cex = 2,col = \"darkorange\",\n xlab = \"Fitted\", ylab = \"S_Residuals_(i)\",\n ylim=c(min(-3, min(s_residual_i)),\n max(3,max(s_residual_i))),\n main = \"studentized residual plot\")\nabline(h=c(-qt(0.975,21-2),0,qt(0.975,21-2)), lty=2)\ntext (fitted(model_reg)[which(abs(s_residual_i)>qt(0.975,21-2))],\n s_residual_i[which(abs(s_residual_i)>qt(0.975,21-2))],\n which(abs(s_residual_i)>qt(0.975,21-2)),adj = c(0,1))"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì •ê·œì„±-ê²€ì •",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì •ê·œì„±-ê²€ì •",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "ì •ê·œì„± ê²€ì •",
    "text": "ì •ê·œì„± ê²€ì •\n\n## ì •ê·œì„± ê²€ì •\npar(mfrow=c(1,2))\nhist(resid(model_reg),\n xlab = \"Residuals\",\n main = \"Histogram of Residuals\",\n col = \"darkorange\",\n border = \"dodgerblue\",\n breaks = 20)\nqqnorm(resid(model_reg),\n main = \"Normal Q-Q Plot\",\n col = \"darkgrey\",\n pch=16)\nqqline(resid(model_reg), col = \"dodgerblue\", lwd = 2)\n\n\n\n\n\n## Shapiro-Wilk Test\n## H0 : normal distribution vs. H1 : not H0\nshapiro.test(resid(model_reg))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(model_reg)\nW = 0.92578, p-value = 0.1133\n\n\n\n## ë…ë¦½ì„± ê²€ì •\nlmtest::dwtest(model_reg)\n\n\n    Durbin-Watson test\n\ndata:  model_reg\nDW = 2.0844, p-value = 0.5716\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n### ë“±ë¶„ì‚°ì„±\n## H0 : ë“±ë¶„ì‚° vs. H1 : ì´ë¶„ì‚° (Heteroscedasticity)\nbptest(model_reg)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model_reg\nBP = 0.0014282, df = 1, p-value = 0.9699"
  },
  {
    "objectID": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì˜í–¥ì ",
    "href": "posts/íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ.html#ì˜í–¥ì ",
    "title": "6. íšŒê·€ì§„ë‹¨ ì‹¤ìŠµ",
    "section": "ì˜í–¥ì ",
    "text": "ì˜í–¥ì \n\nplot(y~x, dt,pch = 20,cex = 2,col = \"darkorange\")\nabline(model_reg, col='steelblue', lwd=2)\n\n\n\n\n\ninfluence(model_reg)\n\n\n\n    $hat\n        10.047922479451021820.15451323429605630.062815775582535340.070545207752054950.047922479451021860.072618957846316370.057989593544981580.056669934394087990.0798582309026469100.0726189578463163110.0907548450343111120.0705452077520549130.0628157755825353140.0566699343940879150.0566699343940879160.0628157755825353170.0521076841867129180.65160998416409190.0530502978659226200.0566699343940879210.0628157755825353\n\n    $coefficients\n        \nA matrix: 21 Ã— 2 of type dbl\n\n    (Intercept)x\n\n\n    1 0.086545033 0.001045618\n    2 0.958749611-0.104156236\n    3-1.623423657 0.057755211\n    4-1.022877601 0.040022565\n    5 0.384830249 0.004649436\n    6 0.005894578-0.001602673\n    7 0.023216186 0.010379001\n    8 0.230329653-0.007159985\n    9 0.410719785-0.017252806\n    10-0.117621441 0.031980023\n    11 1.595051450-0.070799821\n    12-0.437100147 0.017102603\n    13-1.623423657 0.057755211\n    14-1.230320253 0.038245507\n    15 0.412910892-0.012835671\n    16 0.145243868-0.005167222\n    17 0.681955144-0.017203712\n    18 4.243970455-0.347768136\n    19 0.569162106 0.066321856\n    20-1.047739014 0.032569820\n    21 0.145243868-0.005167222\n\n\n\n    $sigma\n        111.3143301900592211.0559573770349310.6687048798294411.1219769595247511.1128596831455611.3246668862836711.2946094952564811.3083981658447911.29861430792641011.20682225901661110.99278346332161211.28816820706241310.66870487982941410.84242194398621511.27164317318071611.31986011811681711.12966417084631811.1067560007425198.628196059920932010.97712792942652111.3198601181168\n\n    $wt.res\n        12.030993137772482-9.572128798733133-15.60395143654324-8.7309403514063859.030993137772416-0.33406228791192573.4119598823618182.5230374783198893.14207073373048106.665937712088081111.015081818867412-3.7309403514063813-15.603951436543214-13.4769625216801154.52303747831988161.39604856345675178.6500263931830218-5.540306160923011930.284970967498720-11.4769625216801211.39604856345675\n\n\n\n\n\ninfluence.measures(model_reg)\n\nInfluence measures of\n     lm(formula = y ~ x, data = dt) :\n\n     dfb.1_    dfb.x    dffit cov.r   cook.d    hat inf\n1   0.01664  0.00328  0.04127 1.166 8.97e-04 0.0479    \n2   0.18862 -0.33480 -0.40252 1.197 8.15e-02 0.1545    \n3  -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n4  -0.20004  0.12788 -0.22433 1.115 2.56e-02 0.0705    \n5   0.07532  0.01487  0.18686 1.085 1.77e-02 0.0479    \n6   0.00113 -0.00503 -0.00857 1.201 3.88e-05 0.0726    \n7   0.00447  0.03266  0.07722 1.170 3.13e-03 0.0580    \n8   0.04430 -0.02250  0.05630 1.174 1.67e-03 0.0567    \n9   0.07907 -0.05427  0.08541 1.200 3.83e-03 0.0799    \n10 -0.02283  0.10141  0.17284 1.152 1.54e-02 0.0726    \n11  0.31560 -0.22889  0.33200 1.088 5.48e-02 0.0908    \n12 -0.08422  0.05384 -0.09445 1.183 4.68e-03 0.0705    \n13 -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n14 -0.24681  0.12536 -0.31367 0.992 4.76e-02 0.0567    \n15  0.07968 -0.04047  0.10126 1.159 5.36e-03 0.0567    \n16  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628    \n17  0.13328 -0.05493  0.18717 1.096 1.79e-02 0.0521    \n18  0.83112 -1.11275 -1.15578 2.959 6.78e-01 0.6516   *\n19  0.14348  0.27317  0.85374 0.396 2.23e-01 0.0531   *\n20 -0.20761  0.10544 -0.26385 1.043 3.45e-02 0.0567    \n21  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628    \n\n\n\nDFFITS: \\(DFFITS(i) = \\dfrac{\\hat y_i - \\tilde y_i(i)}{\\hat \\sigma_{(i)} \\sqrt{h_{ii}}}\\)\n\\(|DFFITS(i)| \\geq 2 \\sqrt{\\dfrac{p+1}{n-p-1}}\\)ì´ë©´ ì˜í–¥ì \n\n\ndffits(model_reg) \n\n10.04127403575140562-0.4025206873025253-0.3911400454742154-0.22432853366080450.1868559838824216-0.0085717364067812270.077223952838937980.056303486522047690.085407472693718100.172840518129759110.33199685399425312-0.094449643042361813-0.39114004547421514-0.313673908094842150.101264129345836160.0329813827461469170.18716612805440518-1.15577873097521190.85373710713076620-0.263846244162542210.0329813827461469\n\n\n\nwhich(abs(dffits(model_reg)) > 2*sqrt(2/(21-2)))\n\n18181919\n\n\n\nCookâ€™s Distance\n\\(D(i) = \\dfrac{\\sum_{i=1}^n (\\hat y_j - \\hat y_j(i))^2}{(p+1)\\hat \\sigma^2}=\\dfrac{(\\hat \\beta - \\hat \\beta(i))^T X^T X (\\hat \\beta - \\hat \\beta(i))}{(p+1) \\hat \\sigma^2}\\)\n\\(\\hat \\beta(i): i\\)ë²ˆì§¸ ê´€ì¸¡ì¹˜ë¥¼ ì œì™¸í•˜ê³  \\(n-1\\)ê°œì˜ ê´€ì¸¡ê°’ì—ì„œ êµ¬í•œ \\(\\hat \\beta\\)ì˜ ìµœì†Œì œê³±ì¶”ì €ëŸ‰\n\n\ncooks.distance(model_reg)\n\n10.00089740639287069120.081497955150763530.071658144221383340.025615958245264150.017743662633501363.87762740910137e-0570.003130574802994980.0016682085781346990.00383194880672965100.0154395158127621110.0548101351203612120.00467762256482442130.0716581442213833140.0475978118328145150.00536121617564154160.000573584529113046170.017856495213809180.678112028575845190.223288273631179200.0345188940892692210.000573584529113046\n\n\n\n\\(D(i) \\geq F_{0.5}(p+1, n-p-1)\\)ì´ë©´ ì˜í–¥ì ìœ¼ë¡œ ì˜ì‹¬\n\n\nqf(0.5,2,21-2)\n\n0.719060569091733\n\n\n\nwhich(cooks.distance(model_reg) >qf(0.5,2,21-2))\n\n\n\n\n\nCOVRATIO\n\n\\(COVRATIO(i) = \\dfrac{1}{\\left[1+\\dfrac{(r_i^*)^2-1}{n-p-1}\\right]^{p+1}(1-h_{ii})}\\)\n\\(|COVRATIO(i)-1| \\geq 3(p+1)/n\\)ì´ë©´ \\(i\\)ë²ˆì§¸ ê´€ì¸¡ì¹˜ë¥¼ ì˜í–¥ì„ í¬ê²Œ ì£¼ëŠ” ì¸¡ì •ê°’ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ\n\ncovratio(model_reg)\n\n11.1658918168321921.1969989767629630.93634739734183941.1151026899392951.0850410825772861.2013199827549771.1701575789867381.1742372676080391.19966823450598101.15209128858604111.08783960928084121.18326164825873130.936347397341839140.992331347870996151.15904532932769161.18673688685713171.09643883044992182.95868271380702190.396431612340971201.04257281407241211.18673688685713\n\n\n\nwhich(abs(covratio(model_reg)-1) > 3*(1+1)/21)\n\n18181919\n\n\n\nì˜í–¥ì \n\n\nsummary(influence.measures(model_reg))\n\nPotentially influential observations of\n     lm(formula = y ~ x, data = dt) :\n\n   dfb.1_ dfb.x   dffit   cov.r   cook.d hat    \n18  0.83  -1.11_* -1.16_*  2.96_*  0.68   0.65_*\n19  0.14   0.27    0.85    0.40_*  0.22   0.05  \n\n\n\n## 18ì œê±° ì „í›„\nplot(y~x, dt,pch = 20,\n cex = 2,col = \"darkorange\",\n main = \"18ë²ˆ ì œê±°\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-18,]), col='red', lwd=2)\ntext(dt[18,], pos=2, \"18\")\nlegend('topright', legend=c(\"full\", \"del(18)\"),\n col=c('steelblue', 'red'), lty=1, lwd=2)\n# high leverage and high influence, not outlier\n\n\n\n\n\n## 19ì œê±° ì „í›„\nplot(y~x, dt,pch = 20,\n cex = 2,col = \"darkorange\",\n main = \"19ë²ˆ ì œê±°\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-19,]), col='red', lwd=2)\ntext(dt[19,], pos=2, \"19\")\nlegend('topright', legend=c(\"full\", \"del(19)\"),\n col=c('steelblue', 'red'), lty=1, lwd=2)\n# not leverage and high influence, outlier\n\n\n\n\n\n## 18, 19ì œê±° ì „í›„\nplot(y~x, dt,pch = 20,\n cex = 2,col = \"darkorange\",\n main = \"18,19ë²ˆ ì œê±°\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-c(18,19),]), col='red', lwd=2)\ntext(dt[c(18,19),], pos=2, c(\"18\",\"19\"))\nlegend('topright', legend=c(\"full\", \"del(18,19)\"),\n col=c('steelblue', 'red'), lty=1, lwd=2)\n\n\n\n\n\n## íšŒê·€ì§„ë‹¨ ê·¸ë¦¼\npar(mfrow = c(2, 2))\nplot(model_reg, pch=16)"
  },
  {
    "objectID": "posts/graph4-3.html",
    "href": "posts/graph4-3.html",
    "title": "CH4. ì§€ë„ ê·¸ë˜í”„ í•™ìŠµ(ê·¸ë˜í”„ ì •ê·œí™” ë°©ë²•)",
    "section": "",
    "text": "ê·¸ë˜í”„ ë¨¸ì‹ ëŸ¬ë‹\ngithub"
  },
  {
    "objectID": "posts/graph4-3.html#load-dataset",
    "href": "posts/graph4-3.html#load-dataset",
    "title": "CH4. ì§€ë„ ê·¸ë˜í”„ í•™ìŠµ(ê·¸ë˜í”„ ì •ê·œí™” ë°©ë²•)",
    "section": "Load Dataset",
    "text": "Load Dataset\n- ë°ì´í„°ì…‹: Cora\n\n7ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¼ë²¨ë§ë¼ ìˆëŠ” 2,708ê°œì˜ ì»´í“¨í„° ì‚¬ì´ì–¸ìŠ¤ ë…¼ë¬¸\nê° ë…¼ë¬¸ì€ ì¸ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ë¥¸ ë…¸ë“œì™€ ì—°ê²°ëœ ë…¸ë“œ\nì´ 5,429ê°œì˜ ê°„ì„ \n\n\nfrom stellargraph import datasets\n\n2023-04-06 21:44:50.486139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n\ndataset = datasets.Cora()\n\n\n%config Completer.use_jedi = False\n\n\ndataset.download()\n\n\nlabel_index = {\n      'Case_Based': 0,\n      'Genetic_Algorithms': 1,\n      'Neural_Networks': 2,\n      'Probabilistic_Methods': 3,\n      'Reinforcement_Learning': 4,\n      'Rule_Learning': 5,\n      'Theory': 6,\n  }\n\n\nG, labels = dataset.load()\n\n\nG: ë„¤íŠ¸ì›Œí¬ ë…¸ë“œ, ê°„ì„ , BOWí‘œí˜„ ì„¤ëª…\nlabea : ë…¼ë¬¸idì™€ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ ì‚¬ì´ì˜ ë§¤í•‘\ní›ˆë ¨ ìƒ˜í”Œ: ì´ì›ƒê³¼ ê´€ë ¨ëœ ì •ë³´ê°€ í¬í•¨ -> í›ˆë ¨ì„ ì •ê·œí™” í•˜ëŠ”ë° ì‚¬ìš©\nê²€ì¦ ìƒ˜í”Œ: ì´ì›ƒê³¼ ê´€ë ¨ëœ ì •ë³´ ë¶ˆí¬í•¨ , ì˜ˆì¸¡ëœ ë¼ë²¨ì€ ë…¸ë“œ íŠ¹ì¦, bowí‘œí˜„ì—ë§Œ ì˜ì¡´\n\n\nimport numpy as np\nfrom sklearn import preprocessing, feature_extraction, model_selection\n\n\nimport tensorflow as tf\nfrom tensorflow.train import Example, Features, Feature, Int64List, BytesList, FloatList\n\n\nGRAPH_PREFIX=\"NL_nbr\"\n\n\ndef _int64_feature(*value):\n    \"\"\"Returns int64 tf.train.Feature from a bool / enum / int / uint.\"\"\"\n    return Feature(int64_list=Int64List(value=list(value)))\n\ndef _bytes_feature(value):\n    \"\"\"Returns bytes tf.train.Feature from a string.\"\"\"\n    return Feature(\n        bytes_list=BytesList(value=[value.encode('utf-8')])\n    )\n\ndef _float_feature(*value):\n    return Feature(float_list=FloatList(value=list(value)))\n\n\n_int64_feature í•¨ìˆ˜ëŠ” bool, enum, int, uint ë°ì´í„° íƒ€ì…ì„ ì…ë ¥ ë°›ì•„ int64_list íƒ€ì…ì˜ tf.train.Feature ê°ì²´ë¥¼ ë°˜í™˜\n_bytes_feature í•¨ìˆ˜ëŠ” ë¬¸ìì—´ ê°’ì„ ì…ë ¥ ë°›ì•„ utf-8ë¡œ ì¸ì½”ë”©í•˜ì—¬ bytes_list íƒ€ì…ì˜ tf.train.Feature ê°ì²´ë¥¼ ë°˜í™˜\n_float_feature í•¨ìˆ˜ëŠ” float ë°ì´í„° íƒ€ì…ì„ ì…ë ¥ ë°›ì•„ float_list íƒ€ì…ì˜ tf.train.Feature ê°ì²´ë¥¼ ë°˜í™˜\n\n- ë°˜ì§€ë„ í•™ìŠµ ë°ì´í„° ì…‹ ë§Œë“œëŠ” í•¨ìˆ˜ ì •ì˜\n\nfrom functools import reduce\nfrom typing import List, Tuple\nimport pandas as pd\nimport six\n\ndef addFeatures(x, y):\n    res = Features()\n    res.CopyFrom(x)\n    res.MergeFrom(y)\n    return res\n\ndef neighborFeatures(features: Features, weight: float, prefix: str):  # ê°ì²´, ê°€ì¤‘ì¹˜, ì ‘ë‘ì–´ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ\n    data = {f\"{prefix}_weight\": _float_feature(weight)}\n    for name, feature in six.iteritems(features.feature):\n        data[f\"{prefix}_{name}\"] = feature \n    return Features(feature=data)\n\ndef neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n    return reduce(\n        addFeatures, \n        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n        Features()\n    )\n\ndef getNeighbors(idx, adjMatrix, topn=5): #ì¸ë±ìŠ¤ì™€ ì¸ì ‘í–‰ë ¬ ì´ìš©í•˜ì—¬ ì´ì›ƒ ë°ì´í„°ì…‹ ì¶”ì¶œ \n    weights = adjMatrix.loc[idx]\n    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n    \n\ndef semisupervisedDataset(G, labels, ratio=0.2, topn=5):  #ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ì™€ ì—†ëŠ” ë°ì´í„° ì¶”ì¶œ\n     #ratio:ë¼ë²¨ ìœ ë¬´ ë¹„ìœ¨ ì„¤ì •\n     #topn: í•¨ìˆ˜ì—ì„œ ì¶”ì¶œí•  ì´ì›ƒ ë°ì´í„°ì…‹ í¬ê¸° ì„¤ì •\n    n = int(np.round(len(labels)*ratio)) \n    \n    labelled, unlabelled = model_selection.train_test_split(\n        labels, train_size=n, test_size=None, stratify=labels\n    )\n\n\n1. ë…¸ë“œ íŠ¹ì§• dfë¡œ êµ¬ì„±í•˜ê³  ê·¸ë˜í”„ ì¸ì ‘í–‰ë ¬ë¡œ ì €ì¥\n\nadjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n    \nfeatures = pd.DataFrame(G.node_features(), index=G.nodes())\n\n\n\n2. adjMatrixì‚¬ìš©í•´ ë…¸ë“œIDì™€ ê°„ì„  ê°€ì¤‘ì¹˜ ë°˜í™˜í•˜ì—¬ ë…¸ë“œì˜ ê°€ì¥ ê°€ê¹Œìš´ TOPNì´ì›ƒ ê²€ìƒ‰í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜ êµ¬í˜„\n\ndef getNeighbors(idx, adjMatrix, topn=5): #ì¸ë±ìŠ¤ì™€ ì¸ì ‘í–‰ë ¬ ì´ìš©í•˜ì—¬ ì´ì›ƒ ë°ì´í„°ì…‹ ì¶”ì¶œ \n    weights = adjMatrix.loc[idx]\n    neighbors = weights[weights>0]\\\n        .sort_values(ascending=False)\\\n        .head(topn)\n    return [(k,v) for k, v in neighbors.iteritems()]\n    \n\n\n3. ì •ë³´ë¥¼ ë‹¨ì¼ dfë¡œ ë³‘í•©\n\ndataset = {\n        index: Features(feature = {\n            #\"id\": _bytes_feature(str(index)), \n            \"id\": _int64_feature(index),\n            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n            \"label\": _int64_feature(label_index[label])\n        })\n        for index, label in pd.concat([labelled, unlabelled]).items()\n    }\n\nNameError: name 'labelled' is not defined\n\n\n\nfrom functools import reduce\nfrom typing import List, Tuple\nimport pandas as pd\nimport six\n\ndef addFeatures(x, y):\n    res = Features()\n    res.CopyFrom(x)\n    res.MergeFrom(y)\n    return res\n\ndef neighborFeatures(features: Features, weight: float, prefix: str):\n    data = {f\"{prefix}_weight\": _float_feature(weight)}\n    for name, feature in six.iteritems(features.feature):\n        data[f\"{prefix}_{name}\"] = feature \n    return Features(feature=data)\n\ndef neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n    return reduce(\n        addFeatures, \n        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n        Features()\n    )\n\ndef getNeighbors(idx, adjMatrix, topn=5):\n    weights = adjMatrix.loc[idx]\n    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n    \n\ndef semisupervisedDataset(G, labels, ratio=0.2, topn=5):\n    n = int(np.round(len(labels)*ratio))\n    \n    labelled, unlabelled = model_selection.train_test_split(\n        labels, train_size=n, test_size=None, stratify=labels\n    )\n    \n    adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n    \n    features = pd.DataFrame(G.node_features(), index=G.nodes())\n    \n    dataset = {\n        index: Features(feature = {\n            #\"id\": _bytes_feature(str(index)), \n            \"id\": _int64_feature(index),\n            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n            \"label\": _int64_feature(label_index[label])\n        })\n        for index, label in pd.concat([labelled, unlabelled]).items()\n    }\n    \n    trainingSet = [\n        Example(features=addFeatures(\n            dataset[exampleId], \n            neighborsFeatures(\n                [(dataset[nodeId], weight) for nodeId, weight in getNeighbors(exampleId, adjMatrix, topn).items()]\n            )\n        ))\n        for exampleId in labelled.index\n    ]\n    \n    testSet = [Example(features=dataset[exampleId]) for exampleId in unlabelled.index]\n\n    serializer = lambda _list: [e.SerializeToString() for e in _list]\n    \n    return serializer(trainingSet), serializer(testSet)"
  },
  {
    "objectID": "posts/í•™íšŒ.html",
    "href": "posts/í•™íšŒ.html",
    "title": "Scribbling",
    "section": "",
    "text": "ì¼ì •:23. 6.29(ëª©) ~ 7.1 (í† )\nì¥ì†Œ: ë¶€ê²½ëŒ€í•™êµ(ë¶€ì‚°)\në°œí‘œì‹ ì²­ ë° ì´ˆë¡ì œì¶œ: 3.20.(ì›”) ~ 4.20.(ëª©)\në°œí‘œìš”ì•½ë³¸ì œì¶œ(ì„ì‚¬ê³¼ì •) : ~4.20.(ëª©)\ní¬ìŠ¤í„°íŒŒì¼ì œì¶œ: ~ 5.19.(ê¸ˆ)\n\n\n\n\n\ní•˜ê³„: 2023. 7.6.(ëª©) ~ 7.7.(ê¸ˆ)\nê³ ë ¤ëŒ€í•™êµ\në°œí‘œì‹ ì²­ ë° ì‚¬ì „ë“±ë¡: 23.5.29.(ì›”)\nì´ˆë¡ ë˜ëŠ” ë…¼ë¬¸ì œì¶œ: ~5.31.(ìˆ˜)\n\n\n\n\n\nì¼ì •: 6.23.(ê¸ˆ) ~ 6.24.(í† )\nì¥ì†Œ: ê°•ë¦‰ì›ì£¼ëŒ€í•™êµ\në°œí‘œë…¼ë¬¸ ì´ˆë¡ ì œì¶œ: ~5.5.(ê¸ˆ)\në°œí‘œ ë…¼ë¬¸ ì œì¶œ: ~6.16.(ê¸ˆ)\ní•™ìƒë…¼ë¬¸: ~6.9.(ê¸ˆ)"
  },
  {
    "objectID": "posts/ë³€ìˆ˜ì„ íƒ ì‹¤ìŠµ.html",
    "href": "posts/ë³€ìˆ˜ì„ íƒ ì‹¤ìŠµ.html",
    "title": "7. ë³€ìˆ˜ì„ íƒ ì‹¤ìŠµ",
    "section": "",
    "text": "dt <- data.frame(\n\n x1 = c(7,1,11,11,7,11,3,1,2,21,1,11,10),\n x2 = c(26,29,56,31,52,55,71,31,54,47,40,66,68),\n x3 = c(6,15,8,8,6,9,17,22,18,4,23,9,8),\n x4 = c(60,52,20,47,33,22,6,44,22,26,34,12,12),\n y = c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,93.1,115.9,83.8,113.3,109.4)\n)\n\n\npairs(dt, pch=16)\ncor(dt)\n\n\n\nA matrix: 5 Ã— 5 of type dbl\n\n    x1x2x3x4y\n\n\n    x1 1.0000000 0.2285795-0.8241338-0.2454451 0.7307175\n    x2 0.2285795 1.0000000-0.1392424-0.9729550 0.8162526\n    x3-0.8241338-0.1392424 1.0000000 0.0295370-0.5346707\n    x4-0.2454451-0.9729550 0.0295370 1.0000000-0.8213050\n    y 0.7307175 0.8162526-0.5346707-0.8213050 1.0000000\n\n\n\n\n\n\n\n\nFull Model : \\(ğ‘¦ = ğ›½_0 + ğ›½_1ğ‘¥_1 + ğ›½_2ğ‘¥_2 + ğ›½_3ğ‘¥_3 + ğ›½_4ğ‘¥_4 + \\epsilon\\)\n\n\nm <- lm(y~., dt) ##FM\nsummary(m)\n\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1750 -1.6709  0.2508  1.3783  3.9254 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  62.4054    70.0710   0.891   0.3991  \nx1            1.5511     0.7448   2.083   0.0708 .\nx2            0.5102     0.7238   0.705   0.5009  \nx3            0.1019     0.7547   0.135   0.8959  \nx4           -0.1441     0.7091  -0.203   0.8441  \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.446 on 8 degrees of freedom\nMultiple R-squared:  0.9824,    Adjusted R-squared:  0.9736 \nF-statistic: 111.5 on 4 and 8 DF,  p-value: 4.756e-07\n\n\n\n\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1750 -1.6709  0.2508  1.3783  3.9254 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  62.4054    70.0710   0.891   0.3991  \nx1            1.5511     0.7448   2.083   0.0708 .\nx2            0.5102     0.7238   0.705   0.5009  \nx3            0.1019     0.7547   0.135   0.8959  \nx4           -0.1441     0.7091  -0.203   0.8441  \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.446 on 8 degrees of freedom\nMultiple R-squared:  0.9824,    Adjusted R-squared:  0.9736 \nF-statistic: 111.5 on 4 and 8 DF,  p-value: 4.756e-07\n\n\n\ndrop1(m, test = \"F\") #x3 ì œê±°\n\n\n\nA anova: 5 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA        NA47.8636426.94429        NA        NA\n    x1 125.950911473.8145530.575884.337474000.07082169\n    x2 1 2.972478250.8361225.727550.496824440.50090110\n    x3 1 0.109090047.9727324.973880.018233470.89592269\n    x4 1 0.246974748.1106125.011200.041279720.84407147\n\n\n\n\n\nm1 <- update(m, ~ . -x3)\nsummary(m1) #x4 ì œê±°\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \nx4           -0.2365     0.1733  -1.365 0.205395    \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\ndrop1(m1, test = \"F\")\n\n\n\nA anova: 4 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA        NA 47.9727324.97388        NA          NA\n    x1 1820.907402868.8801360.62933154.0076355.780764e-07\n    x2 1 26.789383 74.7621128.74170  5.0258655.168735e-02\n    x4 1  9.931754 57.9044825.41999  1.8632622.053954e-01\n\n\n\n\n\nm2 <- update(m1, ~ . -x4)\nsummary(m2) \n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.893 -1.574 -1.302  1.363  4.048 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 52.57735    2.28617   23.00 5.46e-10 ***\nx1           1.46831    0.12130   12.11 2.69e-07 ***\nx2           0.66225    0.04585   14.44 5.03e-08 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.406 on 10 degrees of freedom\nMultiple R-squared:  0.9787,    Adjusted R-squared:  0.9744 \nF-statistic: 229.5 on 2 and 10 DF,  p-value: 4.407e-09\n\n\n\ndrop1(m2, test = \"F\")\n\n\n\nA anova: 3 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA  57.9044825.41999      NA          NA\n    x1 1 848.4319 906.3363459.17799146.52272.692212e-07\n    x2 11207.78231265.6867563.51947208.58185.028960e-08\n\n\n\n\n\n\n\n\nStart model : \\(ğ‘¦ = ğ›½_0 + \\epsilon\\)\n\n\nm0 = lm(y ~ 1, data = dt)\n\n\nadd1(m0,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## x4ì¶”ê°€\n\n\n\nA anova: 5 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA2715.763171.44443       NA          NA\n    x1 11450.07631265.686763.5194712.6025180.0045520446\n    x2 11809.4267 906.336359.1779921.9606050.0006648249\n    x3 1 776.36261939.400569.06740 4.4034170.0597623242\n    x4 11831.8962 883.866958.8516422.7985200.0005762318\n\n\n\n\n\nm1 <- update(m0, ~ . +x4)\nsummary(m1)\n\n\nCall:\nlm(formula = y ~ x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.589  -8.228   1.495   4.726  17.524 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 117.5679     5.2622  22.342 1.62e-10 ***\nx4           -0.7382     0.1546  -4.775 0.000576 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 8.964 on 11 degrees of freedom\nMultiple R-squared:  0.6745,    Adjusted R-squared:  0.645 \nF-statistic:  22.8 on 1 and 11 DF,  p-value: 0.0005762\n\n\n\nadd1(m1,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## x1ì¶”ê°€\n\n\n\nA anova: 4 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA883.8669258.85164         NA          NA\n    x1 1809.10480 74.7621128.74170108.22390931.105281e-06\n    x2 1 14.98679868.8801360.62933  0.17248396.866842e-01\n    x3 1708.12891175.7380039.85258 40.29458028.375467e-05\n\n\n\n\n\nm2 <- update(m1, ~ . +x1)\nsummary(m2)\n\n\nCall:\nlm(formula = y ~ x4 + x1, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0234 -1.4737  0.1371  1.7305  3.7701 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 103.09738    2.12398   48.54 3.32e-13 ***\nx4           -0.61395    0.04864  -12.62 1.81e-07 ***\nx1            1.43996    0.13842   10.40 1.11e-06 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.734 on 10 degrees of freedom\nMultiple R-squared:  0.9725,    Adjusted R-squared:  0.967 \nF-statistic: 176.6 on 2 and 10 DF,  p-value: 1.581e-08\n\n\n\nadd1(m2,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## stop\n\n\n\nA anova: 3 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA      NA74.7621128.74170      NA        NA\n    x2 126.7893847.9727324.973885.0258650.05168735\n    x3 123.9259950.8361225.727554.2358460.06969226\n\n\n\n\n\n\n\n\nm0 = lm(y ~ 1, data = dt)\n\n\nadd1(m0,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## x4ì¶”ê°€\n\n\n\nA anova: 5 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA2715.763171.44443       NA          NA\n    x1 11450.07631265.686763.5194712.6025180.0045520446\n    x2 11809.4267 906.336359.1779921.9606050.0006648249\n    x3 1 776.36261939.400569.06740 4.4034170.0597623242\n    x4 11831.8962 883.866958.8516422.7985200.0005762318\n\n\n\n\n\nm1 <- update(m0, ~ . +x4)\nsummary(m1)\n\n\nCall:\nlm(formula = y ~ x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.589  -8.228   1.495   4.726  17.524 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 117.5679     5.2622  22.342 1.62e-10 ***\nx4           -0.7382     0.1546  -4.775 0.000576 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 8.964 on 11 degrees of freedom\nMultiple R-squared:  0.6745,    Adjusted R-squared:  0.645 \nF-statistic:  22.8 on 1 and 11 DF,  p-value: 0.0005762\n\n\n\nadd1(m1,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## x1ì¶”ê°€\n\n\n\nA anova: 4 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA883.8669258.85164         NA          NA\n    x1 1809.10480 74.7621128.74170108.22390931.105281e-06\n    x2 1 14.98679868.8801360.62933  0.17248396.866842e-01\n    x3 1708.12891175.7380039.85258 40.29458028.375467e-05\n\n\n\n\n\nm2 <- update(m1, ~ . +x1)\n\n\ndrop1(m2, test = \"F\") #ì œê±° ì—†ìŒ\n\n\n\nA anova: 3 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA       NA  74.7621128.74170      NA          NA\n    x4 11190.92461265.6867563.51947159.29521.814890e-07\n    x1 1 809.1048 883.8669258.85164108.22391.105281e-06\n\n\n\n\n\nadd1(m2,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") ## x2ì¶”ê°€\n\n\n\nA anova: 3 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA      NA74.7621128.74170      NA        NA\n    x2 126.7893847.9727324.973885.0258650.05168735\n    x3 123.9259950.8361225.727554.2358460.06969226\n\n\n\n\n\nm3 <- update(m2, ~ . +x2)\nsummary(m3) \n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\ndrop1(m3, test=\"F\") #x4 ì œê±°\n\n\n\nA anova: 4 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA        NA 47.9727324.97388        NA          NA\n    x4 1  9.931754 57.9044825.41999  1.8632622.053954e-01\n    x1 1820.907402868.8801360.62933154.0076355.780764e-07\n    x2 1 26.789383 74.7621128.74170  5.0258655.168735e-02\n\n\n\n\n\nm4 <- update(m3, ~ . -x4)\nsummary(m4)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.893 -1.574 -1.302  1.363  4.048 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 52.57735    2.28617   23.00 5.46e-10 ***\nx1           1.46831    0.12130   12.11 2.69e-07 ***\nx2           0.66225    0.04585   14.44 5.03e-08 ***\n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.406 on 10 degrees of freedom\nMultiple R-squared:  0.9787,    Adjusted R-squared:  0.9744 \nF-statistic: 229.5 on 2 and 10 DF,  p-value: 4.407e-09\n\n\n\nadd1(m4,\n scope = y ~ x1 + x2 + x3+ x4,\n test = \"F\") #stop\n\n\n\nA anova: 3 Ã— 6\n\n    DfSum of SqRSSAICF valuePr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    <none>NA      NA57.9044825.41999      NA       NA\n    x3 19.79386948.1106125.011201.8321280.2088895\n    x4 19.93175447.9727324.973881.8632620.2053954\n\n\n\n\n\n\n\n\n\n\nmodel_back = step(m, direction = \"backward\")\nsummary(model_back)\n\nStart:  AIC=26.94\ny ~ x1 + x2 + x3 + x4\n\n       Df Sum of Sq    RSS    AIC\n- x3    1    0.1091 47.973 24.974\n- x4    1    0.2470 48.111 25.011\n- x2    1    2.9725 50.836 25.728\n<none>              47.864 26.944\n- x1    1   25.9509 73.815 30.576\n\nStep:  AIC=24.97\ny ~ x1 + x2 + x4\n\n       Df Sum of Sq    RSS    AIC\n<none>               47.97 24.974\n- x4    1      9.93  57.90 25.420\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \nx4           -0.2365     0.1733  -1.365 0.205395    \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\n\n\n\nmodel_forward = step(\n m0,\n scope = y ~ x1 + x2 + x3+ x4,\n direction = \"forward\")\nsummary(model_forward)\n\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n<none>              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq    RSS    AIC\n+ x1    1    809.10  74.76 28.742\n+ x3    1    708.13 175.74 39.853\n<none>              883.87 58.852\n+ x2    1     14.99 868.88 60.629\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq    RSS    AIC\n+ x2    1    26.789 47.973 24.974\n+ x3    1    23.926 50.836 25.728\n<none>              74.762 28.742\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n<none>              47.973 24.974\n+ x3    1   0.10909 47.864 26.944\n\n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\n\n\n\nmodel_step = step(\n m0,\n scope = y ~ x1 + x2 + x3+ x4,\n direction = \"both\")\nsummary(model_step)\n\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n<none>              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq     RSS    AIC\n+ x1    1    809.10   74.76 28.742\n+ x3    1    708.13  175.74 39.853\n<none>               883.87 58.852\n+ x2    1     14.99  868.88 60.629\n- x4    1   1831.90 2715.76 71.444\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq     RSS    AIC\n+ x2    1     26.79   47.97 24.974\n+ x3    1     23.93   50.84 25.728\n<none>                74.76 28.742\n- x1    1    809.10  883.87 58.852\n- x4    1   1190.92 1265.69 63.519\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n<none>               47.97 24.974\n- x4    1      9.93  57.90 25.420\n+ x3    1      0.11  47.86 26.944\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n\n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "ë„ì ë„ì  coco ì˜¬ë¦¬ê¸° ì „ ì•„ë¬´ê±°ë‚˜ ë§‰ ì“°ëŠ” ìš©ë„"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scribbling",
    "section": "",
    "text": ":::{#quarto-listing-pipeline .hidden} \\(e = mC^2\\)\n:::{.hidden render-id=â€œpipeline-listing-listingâ€}\n:::{.list .quarto-listing-default}\n\n\n\n\n2023ë…„ í•™íšŒ ë°œí‘œ ì¤€ë¹„\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\në³€ìˆ˜ì„ íƒ ì‹¤ìŠµ\n\n\n\n\n\n\n\nApplied statistics\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nê¹€ë³´ëŒ\n\n\n\n\n\n\n\n\n\níšŒê·€ì§„ë‹¨ ì‹¤ìŠµ\n\n\n\n\n\n\n\nApplied statistics\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2023\n\n\nê¹€ë³´ëŒ\n\n\n\n\n\n\n\n\nCH4. ì§€ë„ ê·¸ë˜í”„ í•™ìŠµ(ê·¸ë˜í”„ ì •ê·œí™” ë°©ë²•)\n\n\n\n\n\n\n\ngraph\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2023\n\n\nê¹€ë³´ëŒ\n\n\n\n\n\n\n\n\nVAE(-ing)\n\n\n\n\n\n\n\nVAE\n\n\nAuto-Encoding Variational Bayes\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2023\n\n\nê¹€ë³´ëŒ\n\n\n\n\n:::\n\n\n\nNo matching items\n\n:::\n:::"
  }
]